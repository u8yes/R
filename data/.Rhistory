# 단계5. 정규분포 시각화
x11()
hist(x1)
# stats 패키지에서 정규성 검정을 위해서 제공되는 시각화 함수.
qqnorm(x1)
qqline(x1, lty=1, col='blue') # 선으로 정규성 여부를 파악하고자 함.
# 단계6. 평균차이 검정
# T-test(T-검정) : 모집단에서 추출한 표본 데이터의 분포형태가 정규분포일 때 수행.
# 1. 양측검정: x1 객체와 기존 모집단의 평균 5.2시간 비교
t.test(x1, mu=5.2) # p-value = 0.0001417 # mu - 기준시간
t.test(x1, mu=5.2, alternative = "two.side", conf.level = 0.95)
# 단계6. 평균차이 검정
# T-test(T-검정) : 모집단에서 추출한 표본 데이터의 분포형태가 정규분포일 때 수행.
# 1. 양측검정: x1 객체와 기존 모집단의 평균 5.2시간 비교
t.test(x1, mu=5.2) # p-value = 0.0001417 # mu - 기준시간
t.test(x1, mu=5.2, alternative = "two.side", conf.level = 0.95)
# 2. 방향성을 갖는 단측가설 검정
t.test(x1, mu=5.2, alternative = "greater", conf.level = 0.95)
# p-value = 7.083e-05(7.083/100000)
t.test(x1, mu=5.2, alternative = "less", conf.level = 0.95)
# 단계1. 실습데이터 가져오기
data <- read.csv("D:/heaven_dev/workspaces/R/data/two_sample.csv", header = T)
head(data)
str(data)
View(data)
# 단계2. 두 집단 subset 작성 및 데이터 전처리
x <- data$method # 교육방법(1:PT,2:Coding)
y <- data$survey # 만족도(1:만족, 0:불만족)
# 단계3. 집단별 빈도분석
table(x)
table(y)
# 단계4. 두 변수에 대한 교차분석
table(x, y, useNA = "ifany") # 결측치까지 출력
# 단계1. 양측 검정
prop.test(c(110,135), c(150,150)) # PT/Coding 교육 방법에 대한 비율 차이 검정.
prop.test(c(110,135), c(150,150), alternative = "two.sided", conf.level = 0.95) # p-value = 0.0003422 => 귀무가설 기각.
# 단계2. 방향성이 있는 단측가설 검정
prop.test(c(110,135), c(150,150), alternative = "greater", conf.level = 0.95)
# p-value = 0.9998 > 0.05(PT > Coding)
prop.test(c(110,135), c(150,150), alternative = "less", conf.level = 0.95) # p-value = 0.0001711(PT < Coding) : 채택
str(data)
# 단계4. 두 변수에 대한 교차분석
table(x, y, useNA = "ifany") # 결측치포함 출력
str(data)
# 단계2. 데이터 분포/결측치 제거
summary(x) # NA's -> 41
# 단계1. 양측 검정
prop.test(c(110,135), c(150,150)) # PT/Coding 교육 방법에 대한 비율 차이 검정. # 40 110 15 135 교차로 넣으면 안 된다.
prop.test(c(110,135), c(150,150), alternative = "two.sided", conf.level = 0.95) # p-value = 0.0003422 => 귀무가설 기각.
# 단계2. 방향성이 있는 단측가설 검정
prop.test(c(110,135), c(150,150), alternative = "greater", conf.level = 0.95)
# p-value = 0.9998 > 0.05(PT > Coding)
prop.test(c(110,135), c(150,150), alternative = "less", conf.level = 0.95) # p-value = 0.0001711(PT < Coding) : 채택
# 단계1. 실습파일 가져오기
data <- read.csv("D:/heaven_dev/workspaces/R/data/two_sample.csv", header = T)
View(data)
str(data)
head(data)
summary(data$score) # score - NA's :73개
# 단계2. 두 집단 subset 작성 및 데이터 전처리
result <- subset(data, !is.na(score), c(method, score))
# 단계3. 정제된 데이터를 대상으로 subset 생성
result
View(result)
# 단계4. 교육 방법별로 분리
a <- subset(result, method == 1)
b <- subset(result, method == 2)
a;b
a1 <- a$score # PT 교육 받은 학생 점수
b1 <- b$score # coding 교육 받은 학생 점수
# 단계5. 기술통계량
length(a1) # [1] 109
length(b1) # [1] 118
mean(a1); mean(b1)
# (2) 동질성 검정
var.test(a1, b1) # p-value = 0.3002 > α(유의수준) : t-검정
# 단계1. 양측검정
t.test(a1, b1)
t.test(a1, b1, alternative = "two.sided", conf.level = 0.95)
# 단계2. 방향성을 갖는 단측가설 검정
t.test(a1, b1, alternative = "greater", conf.level = 0.95)
t.test(a1, b1, alternative = "less", conf.level = 0.95)
# 단계1. 실습 파일 가져오기
data <- read.csv("C:/workspaces/Rwork/src/data/paired_sample.csv", header = T)
# 단계2. 두 집단 subset 작성 및 데이터 전처리
result <- subset(data, !is.na(score), c(method, score))
# 단계3. 정제된 데이터를 대상으로 subset 생성
result
View(result)
View(result)
summary(data$score) # score - NA's :73개
a1 <- a$score # PT 교육 받은 학생 점수
# 단계4. 교육 방법별로 분리
a <- subset(result, method == 1)
b <- subset(result, method == 2)
a;b
a1 <- a$score # PT 교육 받은 학생 점수
b1 <- b$score # coding 교육 받은 학생 점수
# 단계5. 기술통계량
length(a1) # [1] 109
length(b1) # [1] 118
mean(a1); mean(b1)
# (2) 동질성 검정
var.test(a1, b1) # p-value = 0.3002 > α(유의수준) : t-검정
# (2) 동질성 검정
var.test(a1, b1) # p-value = 0.3002 > α(유의수준) : t-검정
# 단계1. 양측검정
t.test(a1, b1)
t.test(a1, b1, alternative = "two.sided", conf.level = 0.95)
# (2) 동질성 검정
var.test(a1, b1) # p-value = 0.3002 > α(유의수준) : t-검정
# 단계1. 양측검정
t.test(a1, b1)
t.test(a1, b1, alternative = "two.sided", conf.level = 0.95)
# 단계5. 기술통계량
length(a1) # [1] 109
length(b1) # [1] 118
mean(a1); mean(b1)
# (2) 동질성 검정
var.test(a1, b1) # p-value = 0.3002 > α(유의수준) : t-검정
# 단계1. 양측검정
t.test(a1, b1)
t.test(a1, b1, alternative = "two.sided", conf.level = 0.95)
# p-value = 0.0411 < 0.05 - 교육방법에 따른 두 집단간 실기시험의 평균에 차이가 있다.
# 차이가 있으니(대립가설 채택) 단측가설 검정정
# 단계2. 방향성을 갖는 단측가설 검정
t.test(a1, b1, alternative = "greater", conf.level = 0.95)
t.test(a1, b1, alternative = "less", conf.level = 0.95)
# 단계1. 실습 파일 가져오기
data <- read.csv("D:/heaven_dev/workspaces/R/data/paired_sample.csv", header = T)
head(data) # no before after
View(data)
summary(data)
# 단계2. 대응 두 집단 subset 생성
result <- subset(data, !is.na(after), c(before, after)) # 96
result
x <- result$before
y <- result$after
result
# 단계2. 대응 두 집단 subset 생성
result <- subset(data, !is.na(after), c(before, after)) # 96
result
x <- result$before
y <- result$after
# 단계3. 기술통계량
length(x) # [1] 96
length(y) # [1] 96
mean(x) # [1] 5.16875
mean(y, na.rm=T) # [1] 6.220833
# (2) 동질성 검정
# 동질성 검정의 귀무가설:대응 두 집단 간 분포의 모양이 동질적이다.
var.test(x, y, paired=T) # p-value = 0.7361
# 단계1: 양측검정
t.test(x, y, paired = T) # p-value < 2.2e-16 : 귀무가설 기각
# 단계2: 방향성을 갖는 단측가설 검정
t.test(x, y, paired = T, alternative = "less", conf.level = 0.95)
t.test(x, y, paired = T, alternative = "greater", conf.level = 0.95)
data <- read.csv("D:/heaven_dev/workspaces/R/data/three_sample.csv", header = T)
View(data)
head(data)
str(data)
summary(data)
# 단계2. 데이터 정제, 전처리
method <- data$method
survey <- data$survey
method; survey
# 단계3. 기술통계량(빈도분석)
table(method, useNA = "ifany")
table(method, survey, useNA = "ifany")
#(2) 세 집단 비율 차이 검정
prop.test(c(34,37,39), c(50,50,50))
prop.test(c(34,37,39), c(50,50,50), alternative = "two.sided", conf.level = 0.95) # p-value = 0.5232(유의확률) > 0.05(유의수준) -> 귀무가설 채택.
# (1) 데이터 전처리
# 단계1. 파일 가져오기
data <- read.csv("D:/heaven_dev/workspaces/R/data/three_sample.csv", header = T)
head(data)
str(data)
summary(data)
# 단계2. 데이터 정제, 전처리
method <- data$method
survey <- data$survey
method; survey
# 단계3. 기술통계량(빈도분석)
table(method, useNA = "ifany")
table(method, survey, useNA = "ifany")
#(2) 세 집단 비율 차이 검정
prop.test(c(34,37,39), c(50,50,50)) # 만족도의 (빈도)값
prop.test(c(34,37,39), c(50,50,50), alternative = "two.sided", conf.level = 0.95) # p-value = 0.5232(유의확률) > 0.05(유의수준) -> 귀무가설 채택.
# (1) 데이터 전처리
# 단계1. 파일 가져오기
data <- read.csv("D:/heaven_dev/workspaces/R/data/three_sample.csv", header = T)
# 단계2. 데이터 정제/전처리 - NA 제거
data <- subset(data, !is.na(score), c(method, score))
data
plot(data$score) # 차트로 outlier 확인 : 50이상과 음수값
barplot(data$score) # 바 차트
mean(data$score) #[1] 14.44725
# 단계4. outlier 제거 - 평균(14.44725)
length(data$score) # [1] 91
data2 <- subset(data, score <= 14) # 14이상 제거
length(data2$score) # [1] 88
data2 <- subset(data, score <= 14) # 14이상 제거
length(data2$score) # [1] 88
# 단계5. 정제된 데이터 보기
x <- data2$score
boxplot(x)
summary(x)
# 단계4. outlier 제거 - 평균(14.44725)
length(data$score) # [1] 91
data2 <- subset(data, score <= 14) # 14이상 제거
length(data2$score) # [1] 88
# 단계5. 정제된 데이터 보기
x <- data2$score
boxplot(x)
summary(x)
# 단계1. 세 집단 subset 작성
data2$method2[data2$method == 1] <- "방법1"
data2$method2[data2$method == 2] <- "방법2"
data2$method2[data2$method == 3] <- "방법3"
View(data2)
# 단계2. 교육 방법별 빈도수
table(data2$method2)
# 단계3. 교육 방법을 x 변수에 저장
x <- table(data2$method2)
x
# 단계4. 교육방법에 따른 시험성적 평균 구하기
y <- tapply(data2$score, data2$method2, mean)
y
# 단계5. 교육방법과 시험성적으로 데이터프레임 생성
df <- data.frame(교육방법 = x, 성적 = y)
df
# (3) 세 집단 간 동질성 검정
bartlett.test(score ~ method2, data = data2)
# (3) 세 집단 간 동질성 검정
bartlett.test(score ~ method2, data = data2)
# (4) 분산분석(세 집단 간 평균 차이 검정)
result <- aov(score ~ method2, data = data2)
result
names(result)
summary(result) # p-value=9.39e-14 : 귀무가설 기각
# (5) 사후검정
TukeyHSD(result) # 분산분석의 결과로 사후검정
plot(TukeyHSD(result))
result
summary(result) # p-value=9.39e-14 : 귀무가설 기각
# (5) 사후검정
TukeyHSD(result) # 분산분석의 결과로 사후검정
plot(TukeyHSD(result))
summary(result) # p-value=9.39e-14 : 귀무가설 기각
# (5) 사후검정
TukeyHSD(result) # 분산분석의 결과로 사후검정
plot(TukeyHSD(result))
# [실습] 변수와 데이터프레임 생성
s1 <- c(1, 2, 1, 2, 3, 4, 2, 3, 4, 5) # s1 : 자연과학
s2 <- c(1, 3, 1, 2, 3, 4, 2, 4, 3, 4) # s2 : 물리화학
s3 <- c(2, 3, 2, 3, 2, 3, 5, 3, 4, 2) # s3 : 인문사회
s4 <- c(2, 4, 2, 3, 2, 3, 5, 3, 4, 1) # s4 : 신문방송
s5 <- c(4, 5, 4, 5, 2, 1, 5, 2, 4, 3) # s5 : 응용수학
s6 <- c(4, 3, 4, 4, 2, 1, 5, 2, 4, 2) # s6 : 추론통계
name <-1:10 # 각 과목 문항 이름
subject <- data.frame(s1, s2, s3, s4, s5, s6)
View(subject)
str(subject)
summary(subject)
# [실습] 변수의 주요 성분분석
pc <- prcomp(subject)
summary(pc)
x11()
plot(pc)
plot(pc)
plot(pc)
str(subject)
summary(subject)
# [실습] 변수의 주요 성분분석
pc <- prcomp(subject)
summary(pc)
# [실습] 변수의 주요 성분분석
pc <- prcomp(subject)
summary(pc)
plot(pc)
# 고유값으로 요인 수 분석
en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터 # cor() 상관분석 알고리즘 # eigen() 고유값
names(en) # "values"  "vectors"
en$values # $values : 고유값(스칼라) 보기
en$vectors
plot(en$values, type="o") # 고유값을 이용한 시각화
# 고유값으로 요인 수 분석 # 2차적으로 검증을 할 수 있다고 볼 수 있다.
en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터 # cor() 상관분석 알고리즘 # eigen() 고유값
names(en) # "values"  "vectors"
en$values # $values : 고유값(스칼라) 보기
en$vectors
plot(en$values, type="o") # 고유값을 이용한 시각화
# [실습] 변수 간의 상관관계 분석과 요인분석
cor(subject)
# 고유값으로 요인 수 분석 # 2차적으로 검증을 할 수 있다고 볼 수 있다.
en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터 # cor() 상관분석 알고리즘 # eigen() 고유값
# 고유값으로 요인 수 분석 # 2차적으로 검증을 할 수 있다고 볼 수 있다.
en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터 # cor() 상관분석 알고리즘 # eigen() 고유값
names(en) # "values"  "vectors"
en$values # $values : 고유값(스칼라) 보기
en$vectors
plot(en$values, type="o") # 고유값을 이용한 시각화
# [실습] 변수 간의 상관관계 분석과 요인분석
cor(subject)
result <- factanal(subject, factors = 2, rotation = "varimax") # 6개 데이터를 2개의 factor로 축약해서 결과를 요인분석
result # p-value is 0.0232  < 0.05 # 요인수가 부족.
# (2) 고유값으로 가정한 3개 요인으로 분석
result <- factanal(subject, factors = 3, rotation = "varimax")
result
result <- factanal(subject, factors = 3, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법
result
# (2) 고유값으로 가정한 3개 요인으로 분석
result <- factanal(subject, factors = 3, rotation = "varimax")
result <- factanal(subject, factors = 4, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법
result
result <- factanal(subject, factors = 4, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법 # 4개는 최적이 아니다.
result <- factanal(subject, factors = 3, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법 # 4개는 최적이 아니다.
result
result <- factanal(subject, factors = 3, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법 # 4개는 최적이 아니다.
result
result <- factanal(subject, factors = 3, # 요인 개수 지정
rotation = "varimax", # 회전방법 지정("varimax", "promax", "none")
scores="regression") # 요인점수 계산 방법 # 4개는 최적이 아니다.
result
# 요인적재량 보기
names(result)
result$loadings
# (3) 다양한 방법으로 요인적재량 보기
print(result, digits = 2, cutoff=0.5)
print(result$loadings, cutoff=0) # display every loadings
result$scores
# 요인적재량 보기
names(result)
result$loadings
# (3) 다양한 방법으로 요인적재량 보기
print(result, digits = 2, cutoff=0.5)
print(result$loadings, cutoff=0) # display every loadings
result$scores
# (1) Factor1, Factor2 요인지표 시각화
plot(result$scores[, c(1:2)], main="Factor1과 Factor2 요인점수 행렬")
text(result$scores[, 1], result$scores[,2],
labels = name, cex = 0.7, pos = 3, col = "blue")
# 요인적재량 plotting
points(result$loadings[, c(1:2)], pch=19, col = "red")
text(result$loadings[, 1], result$loadings[,2],
labels = rownames(result$loadings),
cex = 0.8, pos = 3, col = "red")
text(result$loadings[,1], result$loadings[,3],
labels = rownames(result$loadings),
cex = 0.8, pos = 3, col = "red")
# [실습] 3차원 산점도로 요인적재량 시각화
install.packages("scatterplot3d")
library(scatterplot3d)
Factor1 <- result$scores[,1]
Factor2 <- result$scores[,2]
Factor3 <- result$scores[,3]
# scatterplot3d(밑변, 오른쪽변, 왼쪽변, type='p') # type='p' : 기본산점도 표시
d3 <- scatterplot3d(Factor1, Factor2, Factor3)
# 요인적재량 표시
loadings1 <- result$loadings[,1]
loadings2 <- result$loadings[,2]
loadings3 <- result$loadings[,3]
d3$points3d(loadings1, loadings2, loadings3, bg='red',pch=21, cex=2, type='h')
d3$points3d(loadings1, loadings2, loadings3, bg='red',pch=21, cex=2, type='l')
d3$points3d(loadings1, loadings2, loadings3, bg='red',pch=21, cex=2, type='o')
d3$points3d(loadings1, loadings2, loadings3, bg='red',pch=21, cex=2, type='h')
# [실습] 요인별 변수 묶기
# (1) 요인별 과목변수 이용 데이터프레임 생성
app <- data.frame(subject$s5, subject$s6) # 응용과학
soc <- data.frame(subject$s3, subject$s4) # 사회과학
net <- data.frame(subject$s1, subject$s2) # 자연과학
# (2) 산술평균 계산 - 3개의 파생변수 생성:가독성과 설득력이 높다.
app_science <- round( (app$subject.s5 + app$subject.s6) / ncol(app), 2)
soc_science <- round( (soc$subject.s3 + soc$subject.s4) / ncol(soc), 2)
net_science <- round( (net$subject.s1 + net$subject.s2) / ncol(net), 2)
# (3) 상관관계 분석 - 요인분석을 통해서 만들어진 파생변수는 상관분석이나 회귀분석에서 독립변수로 사용할 수 있다.
subject_factor_df <- data.frame(app_science, soc_science, net_science)
cor(subject_factor_df)
# (2) 산술평균 계산 - 3개의 파생변수 생성:가독성과 설득력이 높다.
app_science <- round( (app$subject.s5 + app$subject.s6) / ncol(app), 2)
soc_science <- round( (soc$subject.s3 + soc$subject.s4) / ncol(soc), 2)
net_science <- round( (net$subject.s1 + net$subject.s2) / ncol(net), 2)
# (3) 상관관계 분석 - 요인분석을 통해서 만들어진 파생변수는 상관분석이나 회귀분석에서 독립변수로 사용할 수 있다.
subject_factor_df <- data.frame(app_science, soc_science, net_science)
cor(subject_factor_df)
# (1) 데이터 가져오기
install.packages('memisc') # spss tool 포맷 파일 읽어오기
library(memisc)
#setwd("D:/heaven_dev/workspaces/R/data/")
data.spss <- as.data.set(spss.system.file('C:/workspaces/Rwork/src/data/drinking_water.sav', , encoded = 'utf-8'))
data.spss
View(data.spss)
#setwd("D:/heaven_dev/workspaces/R/data/")
data.spss <- as.data.set(spss.system.file('D:/heaven_dev/workspaces/R/data/drinking_water.sav', , encoded = 'utf-8'))
data.spss
View(data.spss)
?memisc
#setwd("D:/heaven_dev/workspaces/R/data/")
data.spss <- as.data.set(spss.system.file('D:/heaven_dev/workspaces/R/data/drinking_water.sav', encoded = 'utf-8'))
data.spss
View(data.spss)
data.spss
View(data.spss)
# (2) 데이터프레임으로 변경
drinking_water <- data.spss[1:11]
drinking_water
drinking_water_df <- as.data.frame(drinking_water)
str(drinking_water_df)
View(drinking_water_df)
# (3)  요인수를 3개로 지정하여 요인분석 수행
result2 <- factanal(drinking_water_df, factors = 3, rotation = "varimax",
scores = "regression")
View(drinking_water_df)
# (3)  요인수를 3개로 지정하여 요인분석 수행
result2 <- factanal(drinking_water_df, factors = 3, rotation = "varimax",
scores = "regression")
result2
print(result2, cutoff=0.5)
# (3)  요인수를 3개로 지정하여 요인분석 수행
result2 <- factanal(drinking_water_df, factors = 3, rotation = "varimax",
scores = "regression") # regression 회귀(연속 변수에 대한 데이터 처리)
result2
print(result2, cutoff=0.5)
result2
# 1)  q4 칼럼 제외하여 데이터프레임 생성
dw_df <- drinking_water_df[-4] #제외시킴
str(dw_df)
dim(dw_df) # [1] 380  10
cor(dw_df)
class(dw_df)
names(dw_df) <- c('q1','q2','q3','q5','q6','q7','q8','q9','q10','q11')
dim(dw_df) # [1] 380  10
str(dw_df)
dim(dw_df) # [1] 380  10
cor(dw_df)
class(dw_df)
names(dw_df) <- c('q1','q2','q3','q5','q6','q7','q8','q9','q10','q11')
# 제품만족도 저장 데이터프레임
s <- data.frame(dw_df$q8, dw_df$q9, dw_df$q10, dw_df$q11)
# 제품친밀도 저장 데이터프레임
c <- data.frame(dw_df$q1, dw_df$q2, dw_df$q3)
# 제품적절성 저장 데이터프레임
p <- data.frame(dw_df$q5, dw_df$q6, dw_df$q7)
# 3) 요인별 산술평균 계산
satisfaction <- round( (s$dw_df.q8 + s$dw_df.q9 + s$dw_df.q10 + s$dw_df.q11) / ncol(s), 2)
closeness <- round( (c$dw_df.q1 + c$dw_df.q2 + c$dw_df.q3) / ncol(c), 2)
pertinence <- round( (p$dw_df.q5 + p$dw_df.q6 + p$dw_df.q7) / ncol(p), 2)
# 4) 상관관계 분석
drinking_water_factor_df <- data.frame(satisfaction, closeness, pertinence)
colnames(drinking_water_factor_df) <- c("제품만족도","제품친밀도","제품적절성")
cor(drinking_water_factor_df)
# 3) 요인별 (산술)평균 계산
satisfaction <- round( (s$dw_df.q8 + s$dw_df.q9 + s$dw_df.q10 + s$dw_df.q11) / ncol(s), 2)
closeness <- round( (c$dw_df.q1 + c$dw_df.q2 + c$dw_df.q3) / ncol(c), 2)
pertinence <- round( (p$dw_df.q5 + p$dw_df.q6 + p$dw_df.q7) / ncol(p), 2)
# 4) 상관관계 분석
drinking_water_factor_df <- data.frame(satisfaction, closeness, pertinence)
colnames(drinking_water_factor_df) <- c("제품만족도","제품친밀도","제품적절성")
cor(drinking_water_factor_df)
# [실습] 기술 통계량 구하기
result <- read.csv("D:/heaven_dev/workspaces/R/data/product.csv", header=TRUE)
# [실습] 기술 통계량 구하기
result <- read.csv("D:/heaven_dev/workspaces/R/data/product.csv", header=TRUE)
View(result)
head(result) # 친밀도 적절성 만족도(등간척도 - 5점 척도)
# 기술통계량
summary(result) # 요약통계량
sd(result$제품_친밀도); sd(result$제품_적절성); sd(result$제품_만족도)
# [실습] 기술 통계량 구하기
result <- read.csv("D:/heaven_dev/workspaces/R/data/product.csv", header=TRUE)
View(result)
head(result) # 친밀도 적절성 만족도(등간척도 - 5점 척도)
# 기술통계량
summary(result) # 요약통계량
sd(result$제품_친밀도); sd(result$제품_적절성); sd(result$제품_만족도)
# [실습] 기술 통계량 구하기
result <- read.csv("D:/heaven_dev/workspaces/R/data/product.csv", header=TRUE)
View(result)
head(result) # 친밀도 적절성 만족도(등간척도 - 5점 척도)
# 기술통계량
summary(result) # 요약통계량
sd(result$제품_친밀도); sd(result$제품_적절성); sd(result$제품_만족도)
# [실습] 상관계수(coefficient of correlation) : 두 변량 X,Y 사이의 상관관계 정도를 나타내는 수치(계수)
cor(result$제품_친밀도, result$제품_적절성) # 0.4992086 -> 다소 높은 양의 상관관계
cor(result$제품_친밀도, result$제품_만족도) # 0.467145 -> 다소 높은 양의 상관관계
cor(result)
# [실습] 방향성 있는 색상으로 표현
install.packages("corrgram")
library(corrgram)
corrgram(result) # 색상 적용 - 동일 색상으로 그룹화 표시
corrgram(result, upper.panel=panel.conf) # 수치(상관계수) 추가(위쪽)
corrgram(result, lower.panel=panel.conf) # 수치(상관계수) 추가(아래쪽)
corrgram(result) # 색상 적용 - 동일 색상으로 그룹화 표시
corrgram(result, upper.panel=panel.conf) # 수치(상관계수) 추가(위쪽)
corrgram(result, lower.panel=panel.conf) # 수치(상관계수) 추가(아래쪽)
# [실습] 차트에 밀도 곡선, 상관성, 유의확률(별표) 추가
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
# 상관성,p값(*),정규분포 시각화 - 모수 검정 조건
chart.Correlation(result, histogram=, pch="+")
# [실습]  spearman : 서열척도 대상 상관계수
cor(result, method="spearman")
